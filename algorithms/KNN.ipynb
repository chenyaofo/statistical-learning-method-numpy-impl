{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOY8ZGHKVg+yXmwFQV8GXls",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chenyaofo/statistical-learning-method-numpy-impl/blob/main/algorithms/KNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "y_zuRek-PSXk"
      },
      "outputs": [],
      "source": [
        "import numpy\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from sklearn.datasets import load_svmlight_file\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# we can choose some datasets from libsvm (https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/)\n",
        "# here we choose dataset australian (https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html#australian)\n",
        "# note that here we download the scaled version\n",
        "# set the download_link from the website\n",
        "download_link = \"https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary/australian_scale\"\n",
        "# set the #features from the website\n",
        "n_features = 14\n",
        "# set the test proportion to 50%\n",
        "test_size = 0.5\n",
        "\n",
        "def download_process_data(download_link, n_features, test_size):\n",
        "    r = requests.get(download_link)\n",
        "\n",
        "    X, y = load_svmlight_file(BytesIO(r.content), n_features=n_features)\n",
        "    X = X.toarray()\n",
        "\n",
        "    n_samples, n_features = X.shape\n",
        "    X = numpy.column_stack((X, numpy.ones((n_samples, 1))))\n",
        "    y = y.reshape((-1, 1))\n",
        "\n",
        "    if test_size is None:\n",
        "        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.5)\n",
        "        return X_train, X_val, y_train, y_val\n",
        "    else:\n",
        "        return X, y"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# here we define euclidean metric, other distance metric is also ok\n",
        "def compute_euclidean_distance(a:numpy.array, b:numpy.array):\n",
        "    return numpy.sqrt(((a - b)**2).sum())"
      ],
      "metadata": {
        "id": "u4p4rYCBV4BH"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# here we define a function to find closest set of a given test sample x\n",
        "def find_closest_set(X_train:numpy.array, y_train:numpy.array, x:numpy.array, topk:int):\n",
        "    distances = compute_euclidean_distance(X_train, x)"
      ],
      "metadata": {
        "id": "nQsQl74oZF-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = numpy.random.rand(10)\n",
        "b = numpy.random.rand(10)"
      ],
      "metadata": {
        "id": "i7YRbvZQWotd"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "help(train_test_split)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtjwClgsWz6U",
        "outputId": "bf8fdcab-a341-4198-b2be-f60729e2f964"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on function train_test_split in module sklearn.model_selection._split:\n",
            "\n",
            "train_test_split(*arrays, test_size=None, train_size=None, random_state=None, shuffle=True, stratify=None)\n",
            "    Split arrays or matrices into random train and test subsets.\n",
            "    \n",
            "    Quick utility that wraps input validation and\n",
            "    ``next(ShuffleSplit().split(X, y))`` and application to input data\n",
            "    into a single call for splitting (and optionally subsampling) data in a\n",
            "    oneliner.\n",
            "    \n",
            "    Read more in the :ref:`User Guide <cross_validation>`.\n",
            "    \n",
            "    Parameters\n",
            "    ----------\n",
            "    *arrays : sequence of indexables with same length / shape[0]\n",
            "        Allowed inputs are lists, numpy arrays, scipy-sparse\n",
            "        matrices or pandas dataframes.\n",
            "    \n",
            "    test_size : float or int, default=None\n",
            "        If float, should be between 0.0 and 1.0 and represent the proportion\n",
            "        of the dataset to include in the test split. If int, represents the\n",
            "        absolute number of test samples. If None, the value is set to the\n",
            "        complement of the train size. If ``train_size`` is also None, it will\n",
            "        be set to 0.25.\n",
            "    \n",
            "    train_size : float or int, default=None\n",
            "        If float, should be between 0.0 and 1.0 and represent the\n",
            "        proportion of the dataset to include in the train split. If\n",
            "        int, represents the absolute number of train samples. If None,\n",
            "        the value is automatically set to the complement of the test size.\n",
            "    \n",
            "    random_state : int, RandomState instance or None, default=None\n",
            "        Controls the shuffling applied to the data before applying the split.\n",
            "        Pass an int for reproducible output across multiple function calls.\n",
            "        See :term:`Glossary <random_state>`.\n",
            "    \n",
            "    shuffle : bool, default=True\n",
            "        Whether or not to shuffle the data before splitting. If shuffle=False\n",
            "        then stratify must be None.\n",
            "    \n",
            "    stratify : array-like, default=None\n",
            "        If not None, data is split in a stratified fashion, using this as\n",
            "        the class labels.\n",
            "        Read more in the :ref:`User Guide <stratification>`.\n",
            "    \n",
            "    Returns\n",
            "    -------\n",
            "    splitting : list, length=2 * len(arrays)\n",
            "        List containing train-test split of inputs.\n",
            "    \n",
            "        .. versionadded:: 0.16\n",
            "            If the input is sparse, the output will be a\n",
            "            ``scipy.sparse.csr_matrix``. Else, output type is the same as the\n",
            "            input type.\n",
            "    \n",
            "    Examples\n",
            "    --------\n",
            "    >>> import numpy as np\n",
            "    >>> from sklearn.model_selection import train_test_split\n",
            "    >>> X, y = np.arange(10).reshape((5, 2)), range(5)\n",
            "    >>> X\n",
            "    array([[0, 1],\n",
            "           [2, 3],\n",
            "           [4, 5],\n",
            "           [6, 7],\n",
            "           [8, 9]])\n",
            "    >>> list(y)\n",
            "    [0, 1, 2, 3, 4]\n",
            "    \n",
            "    >>> X_train, X_test, y_train, y_test = train_test_split(\n",
            "    ...     X, y, test_size=0.33, random_state=42)\n",
            "    ...\n",
            "    >>> X_train\n",
            "    array([[4, 5],\n",
            "           [0, 1],\n",
            "           [6, 7]])\n",
            "    >>> y_train\n",
            "    [2, 0, 3]\n",
            "    >>> X_test\n",
            "    array([[2, 3],\n",
            "           [8, 9]])\n",
            "    >>> y_test\n",
            "    [1, 4]\n",
            "    \n",
            "    >>> train_test_split(y, shuffle=False)\n",
            "    [[0, 1, 2], [3, 4]]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# here we set some hyper-parameters\n",
        "topk = 5"
      ],
      "metadata": {
        "id": "VDlUUmV5W1EP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}